{
    "save_csv": true,
    "llm_config": {
        "dataset": "openai/gsm8k",
        "samples": 10,
        "max_new_tokens": 256,
        "togetherai": true,
        "batch_size": 1,
        "model_hf_key": "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "exec_kwargs": {},
        "load_in_8bit": false,
        "load_in_4bit": true,
        "device_map": "auto",
        "read_from_file": false,
        "filename": "runs/openai-gsm8k/processed_ds/llama3_gsm8k_train_test_balanced.xlsx",
        "regression_features_saved": false,
        "regression_features_path": "runs/openai-gsm8k/2024-10-22_08-16-15/regression_features.txt",
        "regression_labels_path": "runs/openai-gsm8k/2024-10-22_08-16-15/regression_labels.txt",
        "verbose": false,
        "class_imbalance": true,
        "fix_class_imbalance": true,
        "hidden_layer": -1,
        "regression_model": "feed forward",
        "epochs": 25

    },
    "wandb_config": {
        "entity": "nlp-sebis",
        "wandb_mode": "online",
        "wandb_project_name": "promtp-tuning-summarization"
    }
}
