Running Inference using Together AI
100%|██████████| 25/25 [00:17<00:00,  1.44it/s]
Inference Results without evaluation are saved to /Users/anumafzal/PycharmProjects/ToTpred/runs/openai-gsm8k/2024-11-05_11-43-22/openai-gsm8k.xlsx
Running Evaluation using GPT-4o mini.
100%|██████████| 25/25 [00:14<00:00,  1.68it/s]
Inference Results with GPT-4o mini evaluation are saved to /Users/anumafzal/PycharmProjects/ToTpred/runs/openai-gsm8k/2024-11-05_11-43-22/openai-gsm8k.xlsx
Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.33s/it]
Some parameters are on the meta device because they were offloaded to the disk.
Generating Features of regression model
  0%|          | 0/25 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
100%|██████████| 25/25 [11:38<00:00, 27.93s/it]
torch.Size([25, 4096])
Saved Regression Features at /Users/anumafzal/PycharmProjects/ToTpred/runs/openai-gsm8k/2024-11-05_11-43-22/regression_features.txt
Saved Regression Labels at /Users/anumafzal/PycharmProjects/ToTpred/runs/openai-gsm8k/2024-11-05_11-43-22/regression_labels.txt
/Users/anumafzal/PycharmProjects/ToTpred/py3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ dense (Dense)                   │ (None, 256)            │     1,048,832 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 128)            │        32,896 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 64)             │         8,256 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (Dense)                 │ (None, 1)              │            65 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 1,090,049 (4.16 MB)
 Trainable params: 1,090,049 (4.16 MB)
 Non-trainable params: 0 (0.00 B)
None
Epoch 1/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 715ms/step - accuracy: 1.0000 - loss: 0.1392
Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to /Users/anumafzal/PycharmProjects/ToTpred/runs/openai-gsm8k/2024-11-05_11-43-22/best_model.keras
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 159ms/step - accuracy: 1.0000 - loss: 0.0981 - val_accuracy: 1.0000 - val_loss: 0.0119
Epoch 2/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 11ms/step - accuracy: 1.0000 - loss: 1.3147e-05
Epoch 2: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 16ms/step - accuracy: 1.0000 - loss: 1.0475e-05 - val_accuracy: 1.0000 - val_loss: 0.0029
Epoch 3/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 10ms/step - accuracy: 1.0000 - loss: 1.2991e-06
Epoch 3: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 16ms/step - accuracy: 1.0000 - loss: 8.6783e-07 - val_accuracy: 1.0000 - val_loss: 6.6523e-04
Epoch 4/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 11ms/step - accuracy: 1.0000 - loss: 1.3555e-07
Epoch 4: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 17ms/step - accuracy: 1.0000 - loss: 9.0367e-08 - val_accuracy: 1.0000 - val_loss: 1.4257e-04
Epoch 5/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 12ms/step - accuracy: 1.0000 - loss: 5.7713e-13
Epoch 5: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 17ms/step - accuracy: 1.0000 - loss: 2.1630e-09 - val_accuracy: 1.0000 - val_loss: 3.2813e-05
Epoch 6/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 11ms/step - accuracy: 1.0000 - loss: 3.1685e-13
Epoch 6: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 15ms/step - accuracy: 1.0000 - loss: 3.8144e-10 - val_accuracy: 1.0000 - val_loss: 8.4928e-06
Epoch 7/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 10ms/step - accuracy: 1.0000 - loss: 5.2011e-10
Epoch 7: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 15ms/step - accuracy: 1.0000 - loss: 3.4674e-10 - val_accuracy: 1.0000 - val_loss: 2.5599e-06
Epoch 8/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 10ms/step - accuracy: 1.0000 - loss: 1.2458e-10
Epoch 8: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 15ms/step - accuracy: 1.0000 - loss: 8.3054e-11 - val_accuracy: 1.0000 - val_loss: 8.7927e-07
Epoch 9/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 10ms/step - accuracy: 1.0000 - loss: 1.3411e-16
Epoch 9: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 15ms/step - accuracy: 1.0000 - loss: 6.6200e-12 - val_accuracy: 1.0000 - val_loss: 3.4611e-07
Epoch 10/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 11ms/step - accuracy: 1.0000 - loss: 1.1736e-11
Epoch 10: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 15ms/step - accuracy: 1.0000 - loss: 7.8239e-12 - val_accuracy: 1.0000 - val_loss: 1.5376e-07
Epoch 11/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 10ms/step - accuracy: 1.0000 - loss: 4.6033e-12
Epoch 11: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 16ms/step - accuracy: 1.0000 - loss: 3.0689e-12 - val_accuracy: 1.0000 - val_loss: 7.6577e-08
Epoch 12/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 11ms/step - accuracy: 1.0000 - loss: 7.6719e-22
Epoch 12: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 17ms/step - accuracy: 1.0000 - loss: 4.8057e-13 - val_accuracy: 1.0000 - val_loss: 4.2123e-08
Epoch 13/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 12ms/step - accuracy: 1.0000 - loss: 1.0366e-12
Epoch 13: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 16ms/step - accuracy: 1.0000 - loss: 6.9104e-13 - val_accuracy: 1.0000 - val_loss: 2.5272e-08
Epoch 14/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 12ms/step - accuracy: 1.0000 - loss: 5.7801e-13
Epoch 14: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 16ms/step - accuracy: 1.0000 - loss: 3.8534e-13 - val_accuracy: 1.0000 - val_loss: 1.6416e-08
Epoch 15/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 10ms/step - accuracy: 1.0000 - loss: 3.5202e-13
Epoch 15: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 14ms/step - accuracy: 1.0000 - loss: 2.3468e-13 - val_accuracy: 1.0000 - val_loss: 1.1410e-08
Epoch 16/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 11ms/step - accuracy: 1.0000 - loss: 1.8562e-20
Epoch 16: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 15ms/step - accuracy: 1.0000 - loss: 6.4607e-14 - val_accuracy: 1.0000 - val_loss: 8.3957e-09
Epoch 17/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 10ms/step - accuracy: 1.0000 - loss: 1.6420e-13
Epoch 17: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 15ms/step - accuracy: 1.0000 - loss: 1.0947e-13 - val_accuracy: 1.0000 - val_loss: 6.4952e-09
Epoch 18/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 13ms/step - accuracy: 1.0000 - loss: 4.3545e-23
Epoch 18: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 16ms/step - accuracy: 1.0000 - loss: 3.5997e-14 - val_accuracy: 1.0000 - val_loss: 5.2439e-09
Epoch 19/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 12ms/step - accuracy: 1.0000 - loss: 3.0512e-23
Epoch 19: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 18ms/step - accuracy: 1.0000 - loss: 2.8810e-14 - val_accuracy: 1.0000 - val_loss: 4.3949e-09
Epoch 20/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 12ms/step - accuracy: 1.0000 - loss: 1.9227e-23
Epoch 20: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 16ms/step - accuracy: 1.0000 - loss: 2.3929e-14 - val_accuracy: 1.0000 - val_loss: 3.7940e-09
Epoch 21/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 12ms/step - accuracy: 1.0000 - loss: 6.6215e-14
Epoch 21: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 17ms/step - accuracy: 1.0000 - loss: 4.4144e-14 - val_accuracy: 1.0000 - val_loss: 3.3574e-09
Epoch 22/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 11ms/step - accuracy: 1.0000 - loss: 1.6614e-21
Epoch 22: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 16ms/step - accuracy: 1.0000 - loss: 1.8034e-14 - val_accuracy: 1.0000 - val_loss: 3.0294e-09
Epoch 23/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 10ms/step - accuracy: 1.0000 - loss: 8.8238e-24
Epoch 23: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 15ms/step - accuracy: 1.0000 - loss: 1.6211e-14 - val_accuracy: 1.0000 - val_loss: 2.7795e-09
Epoch 24/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 10ms/step - accuracy: 1.0000 - loss: 1.1412e-21
Epoch 24: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 15ms/step - accuracy: 1.0000 - loss: 1.4840e-14 - val_accuracy: 1.0000 - val_loss: 2.5882e-09
Epoch 25/25
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 10ms/step - accuracy: 1.0000 - loss: 4.2848e-14
Epoch 25: val_accuracy did not improve from 1.00000
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 15ms/step - accuracy: 1.0000 - loss: 2.8565e-14 - val_accuracy: 1.0000 - val_loss: 2.4399e-09
