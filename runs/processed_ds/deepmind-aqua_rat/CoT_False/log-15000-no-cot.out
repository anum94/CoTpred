 1 Running Inference using Together AI
 2 100%|██████████| 15000/15000 [2:39:00<00:00,  1.57it/s]  
 3 Inference Results without evaluation are saved to /home/aafzal/ToTpred/runs/deepmind-aqua_rat/2024-11-05_17-15-11/CoT_False/deepmind-aqua_rat.xlsx
 4 Running Evaluation using GPT-4o mini.
 5 100%|██████████| 15000/15000 [2:49:27<00:00,  1.48it/s]  
 6 Inference Results with GPT-4o mini evaluation are saved to /home/aafzal/ToTpred/runs/deepmind-aqua_rat/2024-11-05_17-15-11/CoT_False/deepmind-aqua_rat.xlsx
 7  True Labels: 4257, False Labels: 10739
 8 LLM can generate correct answer for 28.38757001867165% of the samples
 9 Using only 8514 samples to fix class imbalance in the dataset.
10 /home/aafzal/ToTpred/py3.10/lib/python3.10/site-packages/accelerate/utils/modeling.py:1462: UserWarning: Current model requires 4224 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.
11   warnings.warn(
12 Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.64it/s]
13 Generating Features of regression model
14   0%|          | 0/8514 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
15  11%|█         | 894/8514 [10:21:41<92:12:50, 43.57s/it]
